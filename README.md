# PrÃ©diction d'Ã‰volution Tumorale - IA en Grande Dimension

## ğŸ“‹ Description du Projet

Ce projet implÃ©mente un systÃ¨me de prÃ©diction de l'Ã©volution tumorale sous traitement en utilisant des techniques d'apprentissage profond avancÃ©es. Le systÃ¨me combine deux approches complÃ©mentaires :

1. **ModÃ¨le de Diffusion** pour la segmentation automatique des tumeurs
2. **AutoEncoder + ConvLSTM** pour la prÃ©diction temporelle de l'Ã©volution tumorale

### Objectif
PrÃ©dire l'Ã©tat d'une tumeur au **Timepoint_5** Ã  partir des donnÃ©es des **Timepoint_1** et **Timepoint_2**.

## ğŸ—ï¸ Architecture du Projet

```
projet_tumeur/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Images NIfTI originales
â”‚   â”‚   â””â”€â”€ PatientID_XX/
â”‚   â”‚       â”œâ”€â”€ Timepoint_1/
â”‚   â”‚       â”œâ”€â”€ Timepoint_2/
â”‚   â”‚       â””â”€â”€ Timepoint_5/
â”‚   â”œâ”€â”€ processed/          # Images prÃ©traitÃ©es (64Ã—128Ã—128)
â”‚   â””â”€â”€ masks/              # Masques gÃ©nÃ©rÃ©s par diffusion
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py      # PrÃ©traitement des donnÃ©es NIfTI
â”‚   â”œâ”€â”€ diffusion_model.py  # ModÃ¨le de diffusion pour segmentation
â”‚   â”œâ”€â”€ autoencoder.py      # AutoEncoder 3D dÃ©bruitant
â”‚   â”œâ”€â”€ convlstm.py         # ConvLSTM pour prÃ©diction temporelle
â”‚   â”œâ”€â”€ train.py            # Pipeline d'entraÃ®nement
â”‚   â”œâ”€â”€ evaluate.py         # Ã‰valuation et mÃ©triques
â”‚   â””â”€â”€ dif1.py             # Version alternative du modÃ¨le de diffusion
â”‚
â””â”€â”€ outputs/
    â”œâ”€â”€ models/             # ModÃ¨les entraÃ®nÃ©s (.pth)
    â”œâ”€â”€ predictions/        # PrÃ©dictions gÃ©nÃ©rÃ©es
    â””â”€â”€ logs/               # Historiques d'entraÃ®nement
```

## ğŸ”§ Installation

### PrÃ©requis
- Python 3.8+
- CUDA compatible GPU (recommandÃ©)
- 16GB+ RAM
- 50GB+ espace disque

### Installation des dÃ©pendances

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install nibabel scipy matplotlib seaborn pandas tqdm scikit-learn opencv-python
```

## ğŸ“Š DonnÃ©es

### Format des DonnÃ©es
- **Format** : NIfTI (.nii.gz)
- **ModalitÃ©** : T1c (T1 avec contraste)
- **Structure** : Un patient par dossier avec 3 timepoints
- **Fichiers par timepoint** :
  - `PatientID_XX_Timepoint_Y_brain_t1c.nii.gz` (image cÃ©rÃ©brale)
  - `PatientID_XX_Timepoint_Y_tumorMask.nii.gz` (masque tumoral)

### PrÃ©traitement
- Redimensionnement Ã  **64Ã—128Ã—128** voxels
- Normalisation Z-score pour les images
- PrÃ©servation des masques binaires (0/1)

## ğŸš€ ExÃ©cution du Projet

### PrÃ©requis avant exÃ©cution

1. **Structure des donnÃ©es** : Placez vos donnÃ©es NIfTI dans `data/raw/` selon cette structure :
```
data/raw/
â”œâ”€â”€ PatientID_01/
â”‚   â”œâ”€â”€ Timepoint_1/
â”‚   â”‚   â”œâ”€â”€ PatientID_01_Timepoint_1_brain_t1c.nii.gz
â”‚   â”‚   â””â”€â”€ PatientID_01_Timepoint_1_tumorMask.nii.gz
â”‚   â”œâ”€â”€ Timepoint_2/
â”‚   â”‚   â”œâ”€â”€ PatientID_01_Timepoint_2_brain_t1c.nii.gz
â”‚   â”‚   â””â”€â”€ PatientID_01_Timepoint_2_tumorMask.nii.gz
â”‚   â””â”€â”€ Timepoint_5/
â”‚       â””â”€â”€ PatientID_01_Timepoint_5_tumorMask.nii.gz
â”œâ”€â”€ PatientID_02/
â””â”€â”€ ...
```

### ExÃ©cution ComplÃ¨te du Pipeline

#### **Ã‰tape 1 : PrÃ©traitement des DonnÃ©es**

```bash
cd src
python data_loader.py
```

**Ce que fait cette Ã©tape :**
- Charge toutes les images NIfTI depuis `data/raw/`
- Redimensionne Ã  64Ã—128Ã—128 voxels
- Applique la normalisation Z-score
- Sauvegarde dans `data/processed/`
- Affiche une visualisation de contrÃ´le

**Temps d'exÃ©cution :** ~5-10 minutes selon le nombre de patients

#### **Ã‰tape 2 : Partie 1 - Segmentation par Diffusion**

```bash
python diffusion_model.py
```

**Ce que fait cette Ã©tape :**
- EntraÃ®ne le modÃ¨le de diffusion UNet3D (8 epochs par dÃ©faut)
- GÃ©nÃ¨re des masques pour tous les timepoints
- Sauvegarde les modÃ¨les dans `outputs/models/`
- CrÃ©e des visualisations dans `outputs/logs/`

**Temps d'exÃ©cution :** ~2-4 heures selon le GPU
**Sorties :**
- `outputs/models/diffusion_model_best.pth`
- `data/masks/PatientID_XX/PatientID_XX_Timepoint_Y_generated_mask_*.nii.gz`

#### **Ã‰tape 3 : Partie 2 - Pipeline AutoEncoder + ConvLSTM**

```bash
python train.py
```

**Ce que fait cette Ã©tape :**
- EntraÃ®ne l'AutoEncoder dÃ©bruitant (20 epochs)
- EntraÃ®ne le modÃ¨le ConvLSTM de prÃ©diction (50 epochs)
- Sauvegarde les meilleurs modÃ¨les
- GÃ©nÃ¨re les courbes d'entraÃ®nement

**Temps d'exÃ©cution :** ~3-6 heures selon le GPU
**Sorties :**
- `outputs/models/autoencoder.pth`
- `outputs/models/best_predictor.pth`
- `outputs/logs/ae_loss_curve.png`
- `outputs/logs/prediction_loss_curve.png`

#### **Ã‰tape 4 : Ã‰valuation et Comparaison**

```bash
python evaluate.py
```

**Ce que fait cette Ã©tape :**
- Ã‰value le modÃ¨le ConvLSTM sur tous les patients
- GÃ©nÃ¨re les prÃ©dictions finales
- Calcule toutes les mÃ©triques (Dice, IoU, etc.)
- Compare avec les masques de diffusion
- CrÃ©e des visualisations complÃ¨tes

**Temps d'exÃ©cution :** ~30 minutes
**Sorties :**
- `outputs/evaluation/evaluation_results.csv`
- `outputs/evaluation/predictions/`
- `outputs/visualization/`

### ğŸš€ ExÃ©cution Rapide (Script Unique)

Si vous voulez exÃ©cuter tout le pipeline d'un coup, crÃ©ez ce script `run_all.py` :

```python
import subprocess
import sys
import os

def run_command(cmd, description):
    print(f"\n{'='*50}")
    print(f"ğŸš€ {description}")
    print(f"{'='*50}")
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    if result.returncode != 0:
        print(f"âŒ Erreur: {result.stderr}")
        sys.exit(1)
    print(f"âœ… {description} terminÃ© avec succÃ¨s")

if __name__ == "__main__":
    os.chdir("src")
    
    # Ã‰tape 1: PrÃ©traitement
    run_command("python data_loader.py", "PrÃ©traitement des donnÃ©es")
    
    # Ã‰tape 2: Diffusion
    run_command("python diffusion_model.py", "EntraÃ®nement modÃ¨le de diffusion")
    
    # Ã‰tape 3: ConvLSTM
    run_command("python train.py", "EntraÃ®nement AutoEncoder + ConvLSTM")
    
    # Ã‰tape 4: Ã‰valuation
    run_command("python evaluate.py", "Ã‰valuation et mÃ©triques")
    
    print("\nğŸ‰ Pipeline complet terminÃ© avec succÃ¨s!")
    print("ğŸ“Š Consultez les rÃ©sultats dans outputs/")
```

Puis exÃ©cutez :
```bash
python run_all.py
```

### ğŸ”§ ExÃ©cution avec Options PersonnalisÃ©es

#### Configuration GPU limitÃ©e :
```bash
# RÃ©duire les paramÃ¨tres pour GPU < 8GB
export CUDA_VISIBLE_DEVICES=0
python train.py --batch_size 1 --patch_size 16,32,32 --epochs 10
```

#### Mode de dÃ©bogage rapide :
```bash
# ExÃ©cution rapide avec moins d'epochs
python train.py --ae_epochs 5 --pred_epochs 10 --debug
```

#### Reprendre l'entraÃ®nement :
```bash
# Reprendre depuis un checkpoint
python train.py --resume outputs/models/best_predictor.pth
```

### ğŸ“‹ VÃ©rification de l'ExÃ©cution

AprÃ¨s chaque Ã©tape, vÃ©rifiez que les fichiers suivants sont crÃ©Ã©s :

**AprÃ¨s prÃ©traitement :**
```bash
ls data/processed/PatientID_*/Timepoint_*/*.nii.gz
```

**AprÃ¨s diffusion :**
```bash
ls data/masks/PatientID_*/
ls outputs/models/diffusion_model_*.pth
```

**AprÃ¨s ConvLSTM :**
```bash
ls outputs/models/autoencoder.pth
ls outputs/models/best_predictor.pth
```

**AprÃ¨s Ã©valuation :**
```bash
ls outputs/evaluation/evaluation_results.csv
ls outputs/evaluation/predictions/*.nii.gz
```

**Pipeline d'entraÃ®nement :**

#### AutoEncoder 3D DÃ©bruitant
- Architecture encoder-decoder avec skip connections
- Compression vers espace latent 128D
- DÃ©bruitage par ajout de bruit gaussien
- Reconstruction avec interpolation trilinÃ©aire

#### ConvLSTM 3D
- Cellules ConvLSTM3D multi-couches
- Integration des features latentes + masques
- PrÃ©diction de l'Ã©volution spatiotemporelle

**Configuration par dÃ©faut :**
```python
config = {
    'batch_size': 1,
    'latent_dim': 128,
    'ae_epochs': 20,
    'pred_epochs': 50,
    'ae_lr': 1e-3,
    'pred_lr': 1e-4,
    'loss_alpha': 0.7,  # Balance BCE/Dice
}
```

### 4. Ã‰valuation

```bash
python evaluate.py
```

**MÃ©triques calculÃ©es :**
- Dice Coefficient
- IoU (Jaccard Index)
- SensibilitÃ©/SpÃ©cificitÃ©
- Distance de Hausdorff

## ğŸ“ˆ RÃ©sultats et Performances

### MÃ©triques Typiques
- **Dice Score** : 0.65-0.85 selon la complexitÃ© tumorale
- **IoU** : 0.50-0.75
- **SensibilitÃ©** : 0.70-0.90

### Visualisations GÃ©nÃ©rÃ©es
- Courbes d'entraÃ®nement (loss, mÃ©triques)
- Comparaisons prÃ©dictions vs. vÃ©ritÃ© terrain
- Distribution des performances par patient
- Matrices de corrÃ©lation entre mÃ©triques

## ğŸ”¬ DÃ©tails Techniques

### AutoEncoder 3D
- **Encoder** : 4 blocs Conv3D avec stride=2
- **Latent** : AdaptiveAvgPool3D + Linear (128D)
- **Decoder** : 4 blocs ConvTranspose3D symÃ©triques
- **RÃ©gularisation** : BatchNorm3D, Dropout

### ConvLSTM 3D
- **Cellules** : Gates classiques (input, forget, output, cell)
- **Architecture** : Multi-couches [64, 32] hidden dims
- **Integration** : ConcatÃ©nation features latentes + masques
- **PrÃ©diction** : Upsampling + Conv3D final avec Sigmoid

### Optimisations MÃ©moire
- Gradient checkpointing
- Mixed precision training (AMP)
- Batch size adaptif
- Nettoyage pÃ©riodique du cache CUDA

## ğŸ“‹ Configuration AvancÃ©e

### HyperparamÃ¨tres Diffusion
```python
TIMESTEPS = 50
BETA_START = 1e-4
BETA_END = 0.02
PATCH_SIZE = (32, 64, 64)
```

### HyperparamÃ¨tres ConvLSTM
```python
hidden_dims = [64, 32]
kernel_sizes = [(3,3,3), (3,3,3)]
grid_size = (4, 4, 4)
```

## ğŸ› DÃ©pannage

### ProblÃ¨mes Courants

**Erreur de mÃ©moire GPU :**
```bash
# RÃ©duire la taille des patches ou batch_size
PATCH_SIZE = (16, 32, 32)
batch_size = 1
```

**Convergence lente :**
```bash
# Ajuster les learning rates
ae_lr = 5e-4
pred_lr = 5e-5
```

**DonnÃ©es manquantes :**
```bash
# VÃ©rifier la structure des dossiers
ls data/raw/PatientID_*/Timepoint_*/
```

## ğŸ“š RÃ©fÃ©rences

1. **Ambiguous Medical Image Segmentation using Diffusion Models** - Segmentation par diffusion
2. **MedSegDiff-V2: Diffusion-Based Medical Image Segmentation with Transformer** - Architecture avancÃ©e
3. **Prediction of Ocean Weather Based on Denoising AutoEncoder and Convolutional LSTM** - Base mÃ©thodologique

## ğŸ¤ Contribution

### Structure des Commits
```bash
git commit -m "feat: ajout modÃ¨le diffusion 3D"
git commit -m "fix: correction memory leak CUDA"
git commit -m "docs: mise Ã  jour README"
```

### Tests
```bash
# Test du pipeline complet
python -m pytest tests/
# Test spÃ©cifique
python src/autoencoder.py  # Test unitaire
```

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© dans le cadre de l'UE "IA en Grande Dimension". 
Usage acadÃ©mique uniquement.

---

## ğŸ¯ Points ClÃ©s du Projet

âœ… **ImplÃ©mentÃ© :**
- ModÃ¨le de diffusion 3D avec UNet
- AutoEncoder dÃ©bruitant 3D
- ConvLSTM pour prÃ©diction temporelle
- Pipeline d'Ã©valuation complet
- Gestion optimisÃ©e de la mÃ©moire

ğŸ”„ **AmÃ©liorations Possibles :**
- Attention mechanisms dans ConvLSTM
- Augmentation de donnÃ©es 3D
- Ensembling de modÃ¨les
- Optimisation hyperparamÃ¨tres par Optuna

ğŸ“Š **RÃ©sultats Attendus :**
- Segmentation prÃ©cise des tumeurs (Dice > 0.7)
- PrÃ©diction fiable de l'Ã©volution temporelle
- Comparaison quantitative diffusion vs. ConvLSTM